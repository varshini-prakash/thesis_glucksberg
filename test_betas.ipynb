{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab557f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydoc import doc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import nibabel as nib\n",
    "import random\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.utils import shuffle\n",
    "import argparse\n",
    "import sys\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import time\n",
    "import os.path\n",
    "from sklearn.model_selection import StratifiedShuffleSplit \n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from ast import literal_eval\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6dbcfdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validaton_logreg(X, y):\n",
    "\n",
    "    best_alphas, results, precision, recall, cm, y_tests, y_preds = [], [], [], [], [], [], []\n",
    "        \n",
    "    for i in range(1):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,test_size =0.1,stratify = y,random_state=i)\n",
    "        model = LogisticRegression(class_weight='balanced', random_state=i,solver = 'lbfgs', penalty = 'l2',max_iter=2000, n_jobs=-1)\n",
    "        scoring = 'balanced_accuracy'\n",
    "        ridge_params = {'C': [0.0001,0.001,0.01, 0.1, 1, 10, 100,1000,10000]}\n",
    "        clf = GridSearchCV(model, ridge_params, scoring=scoring, n_jobs=-1, cv=4)\n",
    "        \n",
    "        print(\"Before normalization\")\n",
    "        print(\"X train sum|min|max\", np.sum(X_train.flat), np.min(X_train), np.max(X_train))\n",
    "        print(\"X test sum|min|max\", np.sum(X_test.flat), np.min(X_test), np.max(X_test))\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        print(\"X train shape\", X_train.shape)\n",
    "        print(\"X test shape\", X_test.shape)\n",
    "        #for data in X_train:\n",
    "        print(\"After normalization\")\n",
    "        print(\"X train sum|min|max\", np.sum(X_train.flat), np.min(X_train), np.max(X_train))\n",
    "        print(\"X test sum|min|max\", np.sum(X_test.flat), np.min(X_test), np.max(X_test))\n",
    "        \n",
    "        pca = PCA(n_components = 0.85)\n",
    "        pca.fit(X_train)\n",
    "        X_train = pca.transform(X_train)\n",
    "        #print(X_train, min(X_train), max(X_train))\n",
    "        X_test = pca.transform(X_test)\n",
    "        print(\"After PCA\")\n",
    "        print(\"X train shape\", X_train.shape)\n",
    "        print(\"X test shape\", X_test.shape)\n",
    "        print(\"X train sum|min|max\", np.sum(X_train.flat), np.min(X_train), np.max(X_train))\n",
    "        print(\"X test sum|min|max\", np.sum(X_test.flat), np.min(X_test), np.max(X_test))\n",
    "        \n",
    "        clf.fit(X_train,y_train)\n",
    "        best_alphas.append(clf.best_params_)\n",
    "        print(clf.best_params_)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        testScore = metrics.accuracy_score(y_test, y_pred)\n",
    "        precision_score = metrics.precision_score(y_test, y_pred, average = 'weighted')\n",
    "        recall_score = metrics.recall_score(y_test, y_pred, average = 'weighted')\n",
    "\n",
    "        results.append(testScore)\n",
    "        precision.append(precision_score)\n",
    "        recall.append(recall_score)\n",
    "\n",
    "        print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "        print(\"Precision:\",precision_score)\n",
    "        print(\"Recall:\",recall_score)\n",
    "\n",
    "        #Confusion Matrix\n",
    "        cnf_matrix = metrics.confusion_matrix(y_test, y_pred, normalize = 'true')\n",
    "        print(cnf_matrix)\n",
    "        cm.append(cnf_matrix)\n",
    "        y_tests.append(y_test)\n",
    "        y_preds.append(y_pred)\n",
    "        \n",
    "        print(\"y train length\", len(y_pred))\n",
    "        print(\"y test length\", len(y_test))\n",
    "        \n",
    "    y_tests = np.array(y_tests)\n",
    "    y_preds = np.array(y_preds)\n",
    "    \n",
    "\n",
    "    \n",
    "    cm = np.array(cm)\n",
    "    \n",
    "    return y_tests,y_preds, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1432cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load betas\n",
    "\n",
    "def load_betas(participant, beta_dir):\n",
    "    \n",
    "    \n",
    "    with open(beta_dir + 'lt_betas/' + participant + '.pkl','rb') as f:\n",
    "        lt_betas = pk.load(f)\n",
    "    \n",
    "    with open(beta_dir + 'lf_betas/' + participant + '.pkl','rb') as f:\n",
    "        lf_betas = pk.load(f)\n",
    "    \n",
    "    with open(beta_dir + 'm_betas/' + participant + '.pkl','rb') as f:\n",
    "        m_betas = pk.load(f)\n",
    "\n",
    "    with open(beta_dir + 'sm_betas/' + participant + '.pkl','rb') as f:\n",
    "        sm_betas = pk.load(f)\n",
    "    \n",
    "    all_betas = np.concatenate((lt_betas, lf_betas, m_betas, sm_betas), axis=0)\n",
    "    return all_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ced7debf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LT LF M SM\n",
    "y_labels = [0]*80 + [1]*40 + [2]*20 + [3]*20\n",
    "beta_dir = '/home/varshini/scratch/data/data_glucksberg/processed_data/betas/alphabetical/'\n",
    "\n",
    "control_p = ['P054','P057','P064','P065','P067','P068','P072','P073','P075','P076','P080','P081']\n",
    "ASD_p     = ['P050','P055','P056','P058','P059','P060','P066','P069','P070','P071','P078','P079']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4882139",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant = 'P075'\n",
    "all_betas = load_betas(participant, beta_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc96ff6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 147456)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_betas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "232da3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization\n",
      "X train sum|min|max -189056.99372839718 -266.3949279785156 204.59457397460938\n",
      "X test sum|min|max -16354.611777435348 -175.83934020996094 192.44900512695312\n",
      "X train shape (144, 147456)\n",
      "X test shape (16, 147456)\n",
      "After normalization\n",
      "X train sum|min|max -3.197442310920451e-13 -5.074716795458659 4.2254815880492815\n",
      "X test sum|min|max 255.4564704465626 -3.925362416560658 5.170043252025262\n",
      "After PCA\n",
      "X train shape (144, 68)\n",
      "X test shape (16, 68)\n",
      "X train sum|min|max -2.984279490192421e-13 -38.36183275743418 39.23375624138189\n",
      "X test sum|min|max -111.45527937527666 -28.156693173146063 23.597786195785325\n",
      "{'C': 100}\n",
      "Accuracy: 0.25\n",
      "Precision: 0.25\n",
      "Recall: 0.25\n",
      "[[0.375 0.25  0.25  0.125]\n",
      " [0.5   0.25  0.    0.25 ]\n",
      " [0.5   0.5   0.    0.   ]\n",
      " [1.    0.    0.    0.   ]]\n",
      "y train length 16\n",
      "y test length 16\n"
     ]
    }
   ],
   "source": [
    "y_tests,y_preds, cm = cross_validaton_logreg(all_betas, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6343badd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
